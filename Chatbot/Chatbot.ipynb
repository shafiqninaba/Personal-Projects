{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple chatbot to determine yes/no based on a given story\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)\n",
    "    \n",
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()\n",
    "\n",
    "all_data = test_data + train_data\n",
    "\n",
    "for story, question , answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))\n",
    "\n",
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) + 1 #+1 for Keras' pad_sequences\n",
    "\n",
    "max_story_len = max([len(data[0]) for data in all_data])\n",
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the data\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "\n",
    "# train/test split\n",
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "\n",
    "# creating a sequence of texts for train set\n",
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers\n",
    "        # Index 0 is reserved\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking vectorized train/test sets\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)\n",
    "\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# placeholders for inputs\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))\n",
    "\n",
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "# encode input sequence and questions\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)\n",
    "\n",
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
    "\n",
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "\n",
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)\n",
    "\n",
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 5s 10ms/step - loss: 1.1889 - accuracy: 0.4819 - val_loss: 0.6940 - val_accuracy: 0.4970\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.7025 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6961 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6951 - accuracy: 0.4990 - val_loss: 0.7011 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6949 - accuracy: 0.5092 - val_loss: 0.6952 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6945 - accuracy: 0.4955 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6945 - accuracy: 0.5059 - val_loss: 0.6935 - val_accuracy: 0.5030\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6950 - accuracy: 0.4885 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6941 - accuracy: 0.5022 - val_loss: 0.6940 - val_accuracy: 0.5030\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6940 - accuracy: 0.4957 - val_loss: 0.6936 - val_accuracy: 0.4800\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6941 - accuracy: 0.4966 - val_loss: 0.6950 - val_accuracy: 0.5010\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6928 - accuracy: 0.5113 - val_loss: 0.6925 - val_accuracy: 0.5030\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6881 - accuracy: 0.5362 - val_loss: 0.6796 - val_accuracy: 0.5570\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6720 - accuracy: 0.5754 - val_loss: 0.6314 - val_accuracy: 0.6600\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6324 - accuracy: 0.6535 - val_loss: 0.6062 - val_accuracy: 0.6760\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6031 - accuracy: 0.6816 - val_loss: 0.5773 - val_accuracy: 0.7020\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5821 - accuracy: 0.6895 - val_loss: 0.5553 - val_accuracy: 0.7070\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5562 - accuracy: 0.7193 - val_loss: 0.5366 - val_accuracy: 0.7410\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5469 - accuracy: 0.7215 - val_loss: 0.5132 - val_accuracy: 0.7530\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5091 - accuracy: 0.7452 - val_loss: 0.4798 - val_accuracy: 0.7560\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4733 - accuracy: 0.7839 - val_loss: 0.4586 - val_accuracy: 0.7900\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4522 - val_accuracy: 0.7850\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4400 - accuracy: 0.7958 - val_loss: 0.4322 - val_accuracy: 0.7850\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4341 - accuracy: 0.7995 - val_loss: 0.4311 - val_accuracy: 0.7910\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4158 - accuracy: 0.8115 - val_loss: 0.4277 - val_accuracy: 0.7940\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4135 - accuracy: 0.8110 - val_loss: 0.4120 - val_accuracy: 0.8030\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3987 - accuracy: 0.8217 - val_loss: 0.3997 - val_accuracy: 0.8140\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3896 - accuracy: 0.8289 - val_loss: 0.3956 - val_accuracy: 0.8210\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3850 - accuracy: 0.8321 - val_loss: 0.3886 - val_accuracy: 0.8270\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3733 - accuracy: 0.8347 - val_loss: 0.3834 - val_accuracy: 0.8240\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3766 - accuracy: 0.8374 - val_loss: 0.3910 - val_accuracy: 0.8300\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3715 - accuracy: 0.8389 - val_loss: 0.3798 - val_accuracy: 0.8360\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3643 - accuracy: 0.8458 - val_loss: 0.3761 - val_accuracy: 0.8320\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3629 - accuracy: 0.8432 - val_loss: 0.3764 - val_accuracy: 0.8360\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3552 - accuracy: 0.8407 - val_loss: 0.3844 - val_accuracy: 0.8320\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3670 - accuracy: 0.8413 - val_loss: 0.3695 - val_accuracy: 0.8360\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3680 - accuracy: 0.8333 - val_loss: 0.3570 - val_accuracy: 0.8370\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3446 - accuracy: 0.8425 - val_loss: 0.3697 - val_accuracy: 0.8340\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3534 - accuracy: 0.8475 - val_loss: 0.3656 - val_accuracy: 0.8370\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3468 - accuracy: 0.8562 - val_loss: 0.3541 - val_accuracy: 0.8410\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3346 - accuracy: 0.8521 - val_loss: 0.3662 - val_accuracy: 0.8280\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3421 - accuracy: 0.8524 - val_loss: 0.3696 - val_accuracy: 0.8340\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3392 - accuracy: 0.8503 - val_loss: 0.3560 - val_accuracy: 0.8330\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3367 - accuracy: 0.8536 - val_loss: 0.3586 - val_accuracy: 0.8330\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3283 - accuracy: 0.8583 - val_loss: 0.3605 - val_accuracy: 0.8290\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3362 - accuracy: 0.8535 - val_loss: 0.3621 - val_accuracy: 0.8330\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3319 - accuracy: 0.8548 - val_loss: 0.3763 - val_accuracy: 0.8270\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3324 - accuracy: 0.8568 - val_loss: 0.3729 - val_accuracy: 0.8260\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3114 - accuracy: 0.8676 - val_loss: 0.3659 - val_accuracy: 0.8350\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3127 - accuracy: 0.8621 - val_loss: 0.3711 - val_accuracy: 0.8320\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3148 - accuracy: 0.8664 - val_loss: 0.3767 - val_accuracy: 0.8220\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3187 - accuracy: 0.8644 - val_loss: 0.3716 - val_accuracy: 0.8360\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3132 - accuracy: 0.8696 - val_loss: 0.3633 - val_accuracy: 0.8290\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3150 - accuracy: 0.8714 - val_loss: 0.3644 - val_accuracy: 0.8390\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3084 - accuracy: 0.8709 - val_loss: 0.3678 - val_accuracy: 0.8330\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3109 - accuracy: 0.8651 - val_loss: 0.3826 - val_accuracy: 0.8330\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3118 - accuracy: 0.8647 - val_loss: 0.3790 - val_accuracy: 0.8280\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3012 - accuracy: 0.8761 - val_loss: 0.3860 - val_accuracy: 0.8210\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3069 - accuracy: 0.8679 - val_loss: 0.3665 - val_accuracy: 0.8400\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3142 - accuracy: 0.8689 - val_loss: 0.3674 - val_accuracy: 0.8330\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3056 - accuracy: 0.8670 - val_loss: 0.3756 - val_accuracy: 0.8270\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2997 - accuracy: 0.8716 - val_loss: 0.3786 - val_accuracy: 0.8320\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3004 - accuracy: 0.8729 - val_loss: 0.3837 - val_accuracy: 0.8350\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2860 - accuracy: 0.8738 - val_loss: 0.3832 - val_accuracy: 0.8290\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3109 - accuracy: 0.8697 - val_loss: 0.3794 - val_accuracy: 0.8330\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3048 - accuracy: 0.8720 - val_loss: 0.3699 - val_accuracy: 0.8330\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2974 - accuracy: 0.8723 - val_loss: 0.3867 - val_accuracy: 0.8320\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3038 - accuracy: 0.8682 - val_loss: 0.4030 - val_accuracy: 0.8230\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2939 - accuracy: 0.8693 - val_loss: 0.4050 - val_accuracy: 0.8280\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2977 - accuracy: 0.8719 - val_loss: 0.4071 - val_accuracy: 0.8310\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2933 - accuracy: 0.8768 - val_loss: 0.3818 - val_accuracy: 0.8290\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2948 - accuracy: 0.8748 - val_loss: 0.3888 - val_accuracy: 0.8300\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2927 - accuracy: 0.8786 - val_loss: 0.4007 - val_accuracy: 0.8330\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3047 - accuracy: 0.8695 - val_loss: 0.3805 - val_accuracy: 0.8270\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2855 - accuracy: 0.8826 - val_loss: 0.3825 - val_accuracy: 0.8240\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2824 - accuracy: 0.8794 - val_loss: 0.3854 - val_accuracy: 0.8270\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2779 - accuracy: 0.8824 - val_loss: 0.4019 - val_accuracy: 0.8310\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2854 - accuracy: 0.8826 - val_loss: 0.3884 - val_accuracy: 0.8330\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2787 - accuracy: 0.8758 - val_loss: 0.3775 - val_accuracy: 0.8360\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2847 - accuracy: 0.8780 - val_loss: 0.3962 - val_accuracy: 0.8300\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2835 - accuracy: 0.8736 - val_loss: 0.4021 - val_accuracy: 0.8330\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2855 - accuracy: 0.8716 - val_loss: 0.4050 - val_accuracy: 0.8320\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2835 - accuracy: 0.8816 - val_loss: 0.4139 - val_accuracy: 0.8330\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2819 - accuracy: 0.8826 - val_loss: 0.4026 - val_accuracy: 0.8270\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2785 - accuracy: 0.8832 - val_loss: 0.3913 - val_accuracy: 0.8370\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2775 - accuracy: 0.8823 - val_loss: 0.4045 - val_accuracy: 0.8250\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2703 - accuracy: 0.8873 - val_loss: 0.3867 - val_accuracy: 0.8250\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2690 - accuracy: 0.8842 - val_loss: 0.4129 - val_accuracy: 0.8270\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2685 - accuracy: 0.8790 - val_loss: 0.4009 - val_accuracy: 0.8340\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2826 - accuracy: 0.8861 - val_loss: 0.4048 - val_accuracy: 0.8250\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2742 - accuracy: 0.8847 - val_loss: 0.4265 - val_accuracy: 0.8210\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2645 - accuracy: 0.8878 - val_loss: 0.4206 - val_accuracy: 0.8180\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2672 - accuracy: 0.8899 - val_loss: 0.4189 - val_accuracy: 0.8310\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2697 - accuracy: 0.8850 - val_loss: 0.4359 - val_accuracy: 0.8200\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2628 - accuracy: 0.8877 - val_loss: 0.4312 - val_accuracy: 0.8220\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2502 - accuracy: 0.8946 - val_loss: 0.4214 - val_accuracy: 0.8250\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2674 - accuracy: 0.8860 - val_loss: 0.4171 - val_accuracy: 0.8310\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2489 - accuracy: 0.8952 - val_loss: 0.4173 - val_accuracy: 0.8240\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2651 - accuracy: 0.8872 - val_loss: 0.4271 - val_accuracy: 0.8260\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2549 - accuracy: 0.8979 - val_loss: 0.4261 - val_accuracy: 0.8210\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2616 - accuracy: 0.8878 - val_loss: 0.4288 - val_accuracy: 0.8290\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2536 - accuracy: 0.8949 - val_loss: 0.4007 - val_accuracy: 0.8230\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2574 - accuracy: 0.8932 - val_loss: 0.4271 - val_accuracy: 0.8180\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2577 - accuracy: 0.8891 - val_loss: 0.4119 - val_accuracy: 0.8200\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2585 - accuracy: 0.8909 - val_loss: 0.4350 - val_accuracy: 0.8240\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2605 - accuracy: 0.8928 - val_loss: 0.4225 - val_accuracy: 0.8320\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2500 - accuracy: 0.8938 - val_loss: 0.4210 - val_accuracy: 0.8300\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2497 - accuracy: 0.8933 - val_loss: 0.4189 - val_accuracy: 0.8260\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2549 - accuracy: 0.8931 - val_loss: 0.4222 - val_accuracy: 0.8260\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2551 - accuracy: 0.8911 - val_loss: 0.4186 - val_accuracy: 0.8240\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2558 - accuracy: 0.8907 - val_loss: 0.4181 - val_accuracy: 0.8290\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2462 - accuracy: 0.8971 - val_loss: 0.4264 - val_accuracy: 0.8200\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2463 - accuracy: 0.9014 - val_loss: 0.4411 - val_accuracy: 0.8110\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2390 - accuracy: 0.9013 - val_loss: 0.4332 - val_accuracy: 0.8300\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2538 - accuracy: 0.8896 - val_loss: 0.4404 - val_accuracy: 0.8230\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2432 - accuracy: 0.8945 - val_loss: 0.4387 - val_accuracy: 0.8290\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2427 - accuracy: 0.9003 - val_loss: 0.4471 - val_accuracy: 0.8130\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2542 - accuracy: 0.8929 - val_loss: 0.4521 - val_accuracy: 0.8190\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2413 - accuracy: 0.8999 - val_loss: 0.4522 - val_accuracy: 0.8270\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2455 - accuracy: 0.8987 - val_loss: 0.4543 - val_accuracy: 0.8180\n"
     ]
    }
   ],
   "source": [
    "# train (comment out if not training)\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting out training history\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment this cell out of not training\n",
    "filename = 'chatbot_120_epochs_v2.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating on a given test set\n",
    "# input model into filename\n",
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n",
      "Is John in the kitchen ?\n",
      "True Test Answer from Data is: no\n",
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9998342\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "# Displaying story and prediction\n",
    "\n",
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)\n",
    "\n",
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)\n",
    "\n",
    "print(\"True Test Answer from Data is:\",test_data[0][2])\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'back, there, garden, down, no, John, put, ., ?, bathroom, Sandra, grabbed, left, journeyed, hallway, Mary, football, went, to, yes, moved, up, apple, milk, the, took, kitchen, got, dropped, Is, office, Daniel, in, picked, bedroom, travelled, discarded'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can only use words from the vocab\n",
    "', '.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story:  John left the kitchen . Sandra dropped the football in the garden .\n",
      "Question:  Is the football in the garden ?\n",
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.9962836\n"
     ]
    }
   ],
   "source": [
    "# Using my own story and question\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()\n",
    "\n",
    "my_question = \"Is the football in the garden ?\"\n",
    "\n",
    "print('Story: ', my_story)\n",
    "print('Question: ',my_question)\n",
    "\n",
    "mydata = [(my_story.split(),my_question.split(),'yes')]\n",
    "my_story,my_ques,my_ans = vectorize_stories(mydata)\n",
    "pred_results = model.predict(([ my_story, my_ques]))\n",
    "\n",
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
