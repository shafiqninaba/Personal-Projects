{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code generates text after being fed words from the story of Moby Dick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in files as string\n",
    "def read_file(filepath):\n",
    "    \n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "        \n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and clean text\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg',disable=['parser','tagger','ner'])\n",
    "\n",
    "# changing default max length\n",
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuations\n",
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file('melville-moby_dick.txt')\n",
    "tokens = separate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize into sequences of tokens\n",
    "train_len = 25+1 # 50 training words , then one target word\n",
    "\n",
    "# Empty list of sequences\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    \n",
    "    # Grab train_len# amount of characters\n",
    "    seq = tokens[i-train_len:i]\n",
    "    \n",
    "    # Add to list of sequences\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras tokenization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences)\n",
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "\n",
    "# convert to Numpy matrix\n",
    "import numpy as np\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a long short term memory based model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding\n",
    "\n",
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, 25, input_length=seq_len))\n",
    "    model.add(LSTM(150, return_sequences=True))\n",
    "    model.add(LSTM(150))\n",
    "    model.add(Dense(150, activation='relu'))\n",
    "\n",
    "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train/test\n",
    "from keras.utils import to_categorical\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocabulary_size+1)\n",
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading trained model\n",
    "from keras.models import load_model\n",
    "model = load_model('epochBIG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating new text\n",
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "\n",
    "#     INPUTS:\n",
    "#     model : model that was trained on text data\n",
    "#     tokenizer : tokenizer that was fit on text data\n",
    "#     seq_len : length of training sequence\n",
    "#     seed_text : raw string text to serve as the seed\n",
    "#     num_gen_words : number of words to be generated by model\n",
    "\n",
    "    \n",
    "    # Final Output\n",
    "    output_text = []\n",
    "    \n",
    "    # Intial Seed Sequence\n",
    "    input_text = seed_text\n",
    "    \n",
    "    # Create num_gen_words\n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        # Take the input text string and encode it to a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        # Pad sequences to the trained rate\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        \n",
    "        # Predict Class Probabilities for each word\n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
    "        \n",
    "        # Grab word\n",
    "        pred_word = tokenizer.index_word[pred_word_ind] \n",
    "        \n",
    "        # Update the sequence of input text (shifting one over with the new word)\n",
    "        input_text += ' ' + pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    # Make it look like a sentence.\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing a random seed sequence\n",
    "import random\n",
    "random.seed(101)\n",
    "random_pick = random.randint(0,len(text_sequences))\n",
    "\n",
    "random_seed_text = text_sequences[random_pick]\n",
    "seed_text = ' '.join(random_seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 words: \n",
      " stranger that stubb vowed he recognised his cutting spade pole entangled in the lines that were knotted round the tail of one of these whales there\n",
      "\n",
      "\n",
      "Original 50 words after: \n",
      " 's a pretty fellow now he banteringly laughed standing in the ship 's bows there 's a jackal for ye i well know that these crappoes of frenchmen are but poor devils in the fishery sometimes lowering their boats for breakers mistaking them for sperm whale spouts yes and sometimes sailing from\n",
      "\n",
      "Generated 50 words after: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shafiq\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my epitaphs to the secondly of this crew whiteness monster wo suspended and well earthly veteran his last cloaked in the sea thumb was the hull spring over to it now wore to it terrific only caused what larger as a try 's yellow in some skull the turned spring\n"
     ]
    }
   ],
   "source": [
    "# Comparing generated text to original text\n",
    "print('First 25 words: \\n',' '.join(text_sequences[random_pick]))\n",
    "print('\\n')\n",
    "print('Original 50 words after: \\n',' '.join(text_sequences[random_pick+26]),end=' ')\n",
    "print(' '.join(text_sequences[random_pick+52]))\n",
    "\n",
    "print('\\nGenerated 50 words after: ')\n",
    "print(generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
